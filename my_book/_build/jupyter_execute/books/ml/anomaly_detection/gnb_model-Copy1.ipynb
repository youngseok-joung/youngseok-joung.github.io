{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26757ba9",
   "metadata": {},
   "source": [
    "# Gaussian naive bayes classifier\n",
    "\n",
    "In statistics, naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features (see Bayes classifier). They are among the simplest Bayesian network models,[1] but coupled with kernel density estimation, they can achieve higher accuracy levels.[2][3]\n",
    "\n",
    "Naïve Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. Maximum-likelihood training can be done by evaluating a closed-form expression,[4]: 718  which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.\n",
    "\n",
    "In the statistics and computer science literature, naive Bayes models are known under a variety of names, including simple Bayes and independence Bayes.[5] All these names reference the use of Bayes' theorem in the classifier's decision rule, but naïve Bayes is not (necessarily) a Bayesian method.[4][5] (https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "\n",
    "\n",
    "## argmin/argmax\n",
    "Arguments of min, arguments of max, meaning that domains which make a function maximum or minimum. (https://www.latex4technics.com/?note=PMQWIE)\n",
    "(https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index)\n",
    "(https://www.math-linux.com/latex-26/faq/latex-faq/article/latex-derivatives-limits-sums-products-and-integrals)\n",
    "\n",
    "For example, the following equation means the value of x where f(x) has the minimum value.\n",
    "\n",
    "$\\argmax\\limits_x f(x)$ \n",
    "\n",
    "If f(x) is $y = x^2 + 3x - 2$, it has a minimum value of ${\\dfrac{10}{4}}$ at ${x = -\\dfrac{3}{2}}$.\n",
    "\n",
    "$\\argmax\\limits_x f(x) = -\\dfrac{3}{2}$\n",
    "\n",
    "## Constructing a classifier from the probability model\n",
    "The discussion so far has derived the independent feature model, that is, the naïve Bayes probability model. The naïve Bayes classifier combines this model with a decision rule. One common rule is to pick the hypothesis that is most probable; this is known as the maximum a posteriori or MAP decision rule. The corresponding classifier, a Bayes classifier, is the function that assigns a class label ${\\displaystyle {\\hat {y}}=C_{k}}{\\hat  {y}}=C_{k}$ for some k as follows:\n",
    "\n",
    "$\\hat{y} = \\argmax\\limits_{k \\in \\mathcal{\\{1, ..., K\\}}} p(C_k) \\prod\\limits_{i=1}^{n} p(x_i | C_k)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de103ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gnb_model.py: \n",
    "\n",
    "This model is the implementation of Gaussian Naive Bayes Classification of KDD datasets.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Youngseok Joung'\n",
    "__copyright__ = \"Copyright 2007, The Cogent Project\"\n",
    "__credits__ = [\"Youngseok Joung\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.1\"\n",
    "__maintainer__ = \"Youngseok Joung\"\n",
    "__email__ = \"none\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import cProfile\n",
    "import pstats\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b22324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoding(model_name, data):\n",
    "    for column in data.columns:\n",
    "        # If the data type of the cell is 'object'(Categorical), it will be transformed as a numerical \n",
    "        if data[column].dtype == type(object):\n",
    "            le_file_path = 'result/' + model_name + '/' + model_name + '_' + column + '_encoder.pkl'\n",
    "#             print(os.path.exists(le_file_path))\n",
    "            if os.path.exists(le_file_path):\n",
    "                pkl_file = open(le_file_path, 'rb')\n",
    "                le = pickle.load(pkl_file) \n",
    "                pkl_file.close()\n",
    "                data[column] = le.transform(data[column])            \n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                data[column] = le.fit_transform(data[column])\n",
    "                #exporting the departure encoder\n",
    "                output = open(le_file_path, 'wb')\n",
    "                pickle.dump(le, output)\n",
    "                output.close()\n",
    "            if column == 'result':\n",
    "                le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(le_name_mapping)\n",
    "                \n",
    "    return data, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b798dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(model_name, data):\n",
    "    y = data.result\n",
    "    x = data.drop('result', axis=1)\n",
    "    \n",
    "    # Preprocessing: Split 7:3 Train: Test\n",
    "    x_train, x_test, y_train, y_test = splitter(x, y, test_size=0.3)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7377e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model_name, x_train, x_test, y_train, y_test):\n",
    "    # Profile: Start \n",
    "    profile = cProfile.Profile()\n",
    "    profile.enable()\n",
    "    \n",
    "    # train and test\n",
    "    model = GaussianNB()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Profile: End \n",
    "    profile.disable()\n",
    "    profile.dump_stats('output.prof')\n",
    "    stream = open('result/' + model_name + '/' + model_name + '_profiling.txt', 'w')\n",
    "    stats = pstats.Stats('output.prof', stream=stream)\n",
    "    stats.sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    os.remove('output.prof')\n",
    "    \n",
    "    # Estimation: Confusion Matrix & classification-report \n",
    "    _confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    _classification_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    with open('result/' + model_name + '/' + model_name + '_output.txt', 'w') as f:\n",
    "        f.write(\"\\n---Confusion Matrix---\\n\")\n",
    "        f.write(np.array2string(_confusion_matrix, separator=', '))\n",
    "        f.write(\"\\n---Classification Report---\\n\")\n",
    "        f.write(_classification_report)\n",
    "\n",
    "    # Freezing model for production \n",
    "    dump(model, 'result/' + model_name + '/' + model_name + '_model.joblib') \n",
    "    \n",
    "    return _confusion_matrix, _classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d30cebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        duration protocol_type   service  flag  src_bytes  dst_bytes      land  \\\n",
      "0     -0.106216           tcp      smtp    SF  -0.003736  -0.040352 -0.011722   \n",
      "1     -0.107850           tcp      http    SF  -0.004276  -0.036652 -0.011722   \n",
      "2     -0.107850           tcp      http    SF  -0.004262   0.005956 -0.011722   \n",
      "3     -0.107033           tcp       ftp    SF  -0.003699  -0.006723 -0.011722   \n",
      "4     -0.107850           udp  domain_u    SF  -0.004368  -0.044940 -0.011722   \n",
      "...         ...           ...       ...   ...        ...        ...       ...   \n",
      "13446 -0.107850           tcp      http    SF  -0.004225   0.049683 -0.011722   \n",
      "13447 -0.107850           tcp      nntp  RSTO  -0.004392  -0.047028 -0.011722   \n",
      "13448 -0.107033           tcp      smtp    SF  -0.003734  -0.041519 -0.011722   \n",
      "13449 -0.107850           tcp      nnsp   REJ  -0.004392  -0.047028 -0.011722   \n",
      "13450 -0.107850           tcp      link    S0  -0.004392  -0.047028 -0.011722   \n",
      "\n",
      "       wrong_fragment    urgent        hot  ...  num_compromised  root_shell  \\\n",
      "0           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "1           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "2           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "3           -0.084394 -0.004737  19.554084  ...        -0.007905    -0.01944   \n",
      "4           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "...               ...       ...        ...  ...              ...         ...   \n",
      "13446       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13447       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13448       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13449       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13450       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "\n",
      "       su_attempted  num_root  num_file_creations  num_shells  \\\n",
      "0         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "1         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "2         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "3         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "4         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "...             ...       ...                 ...         ...   \n",
      "13446     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13447     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13448     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13449     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13450     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "\n",
      "       num_access_files  is_guest_login     count  result  \n",
      "0             -0.050883       -0.068756 -0.731403  normal  \n",
      "1             -0.050883       -0.068756 -0.681570  normal  \n",
      "2             -0.050883       -0.068756 -0.711470  normal  \n",
      "3             -0.050883       14.544119 -0.731403     r2l  \n",
      "4             -0.050883       -0.068756 -0.302843  normal  \n",
      "...                 ...             ...       ...     ...  \n",
      "13446         -0.050883       -0.068756 -0.243044  normal  \n",
      "13447         -0.050883       -0.068756  0.484511     dos  \n",
      "13448         -0.050883       -0.068756 -0.731403  normal  \n",
      "13449         -0.050883       -0.068756  0.265248     dos  \n",
      "13450         -0.050883       -0.068756  1.929653     dos  \n",
      "\n",
      "[13451 rows x 22 columns]>\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gnb_kdd'\n",
    "# model_name = 'xgboost_nsl_kdd'\n",
    "dataset_name = 'kdd_prediction'\n",
    "# dataset_name = 'kdd_prediction_NSL'\n",
    "\n",
    "data = pd.read_csv('./dataset/' + dataset_name + '.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0344ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dos': 0, 'normal': 1, 'probe': 2, 'r2l': 3, 'u2r': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyanJoung\\OneDrive - Datapod Pty Ltd\\Desktop\\uc\\mybook\\my_book\\venv\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.24.1 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# labeling\n",
    "data, _ = labelEncoding(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0360ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "x_train, x_test, y_train, y_test = Preprocessing(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b516ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Confusion Matrix-----\n",
      "\n",
      "[[  74    6 1465   14    1]\n",
      " [1418  501  238   23    6]\n",
      " [   2    0  148    1    0]\n",
      " [   2    4    4  116    0]\n",
      " [   0    2    2    2    7]]\n",
      "\n",
      "-----Classification Report-----\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.05      0.05      1560\n",
      "           1       0.98      0.23      0.37      2186\n",
      "           2       0.08      0.98      0.15       151\n",
      "           3       0.74      0.92      0.82       126\n",
      "           4       0.50      0.54      0.52        13\n",
      "\n",
      "    accuracy                           0.21      4036\n",
      "   macro avg       0.47      0.54      0.38      4036\n",
      "weighted avg       0.58      0.21      0.25      4036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and Test\n",
    "cm, cr = train_and_test(model_name, x_train, x_test, y_train, y_test)\n",
    "print('\\n-----Confusion Matrix-----\\n')\n",
    "print(cm)\n",
    "print('\\n-----Classification Report-----\\n')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5550a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(model_name, data):\n",
    "    real_data, le = labelEncoding(model_name, data)\n",
    "    real_y = real_data.result\n",
    "    real_x = real_data.drop('result', axis=1)\n",
    "#     print(real_y)\n",
    "#     print(real_x)\n",
    "\n",
    "    clf = load('result/' + model_name + '/' + model_name + '_model.joblib')\n",
    "    yy_pred = clf.predict(real_x)\n",
    "    pred_label = le.inverse_transform(yy_pred)\n",
    "    real_label = le.inverse_transform(real_y)\n",
    "\n",
    "    return pred_label, real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8d01f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dos': 0, 'normal': 1, 'probe': 2, 'r2l': 3, 'u2r': 4}\n",
      "['dos'] ['normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RyanJoung\\OneDrive - Datapod Pty Ltd\\Desktop\\uc\\mybook\\my_book\\venv\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.24.1 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Production\n",
    "real_data = pd.read_csv('./dataset/kdd_prediction.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "real_data = real_data.head(1)\n",
    "\n",
    "pred_label, real_label = production(model_name, real_data)\n",
    "print(pred_label, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b274d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}