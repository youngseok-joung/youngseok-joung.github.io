{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26757ba9",
   "metadata": {},
   "source": [
    "# Gaussian naive bayes classifier\n",
    "\n",
    "In statistics, naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features (see Bayes classifier). They are among the simplest Bayesian network models,[1] but coupled with kernel density estimation, they can achieve higher accuracy levels.[2][3]\n",
    "\n",
    "Naïve Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. Maximum-likelihood training can be done by evaluating a closed-form expression,[4]: 718  which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.\n",
    "\n",
    "In the statistics and computer science literature, naive Bayes models are known under a variety of names, including simple Bayes and independence Bayes.[5] All these names reference the use of Bayes' theorem in the classifier's decision rule, but naïve Bayes is not (necessarily) a Bayesian method.[4][5] (https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "\n",
    "\n",
    "## argmin/argmax\n",
    "Arguments of min, arguments of max, meaning that domains which make a function maximum or minimum. (https://www.latex4technics.com/?note=PMQWIE)\n",
    "(https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index)\n",
    "(https://www.math-linux.com/latex-26/faq/latex-faq/article/latex-derivatives-limits-sums-products-and-integrals)\n",
    "\n",
    "For example, the following equation means the value of x where f(x) has the minimum value.\n",
    "\n",
    "$\\argmax\\limits_x f(x)$ \n",
    "\n",
    "If f(x) is $y = x^2 + 3x - 2$, it has a minimum value of ${\\dfrac{10}{4}}$ at ${x = -\\dfrac{3}{2}}$.\n",
    "\n",
    "$\\argmax\\limits_x f(x) = -\\dfrac{3}{2}$\n",
    "\n",
    "## Constructing a classifier from the probability model\n",
    "The discussion so far has derived the independent feature model, that is, the naïve Bayes probability model. The naïve Bayes classifier combines this model with a decision rule. One common rule is to pick the hypothesis that is most probable; this is known as the maximum a posteriori or MAP decision rule. The corresponding classifier, a Bayes classifier, is the function that assigns a class label ${\\displaystyle {\\hat {y}}=C_{k}}{\\hat  {y}}=C_{k}$ for some k as follows:\n",
    "\n",
    "$\\hat{y} = \\argmax\\limits_{k \\in \\mathcal{\\{1, ..., K\\}}} p(C_k) \\prod\\limits_{i=1}^{n} p(x_i | C_k)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de103ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gnb_model.py: \n",
    "\n",
    "This model is the implementation of Gaussian Naive Bayes Classification of KDD datasets.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Youngseok Joung'\n",
    "__copyright__ = \"Copyright 2007, The Cogent Project\"\n",
    "__credits__ = [\"Youngseok Joung\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.1\"\n",
    "__maintainer__ = \"Youngseok Joung\"\n",
    "__email__ = \"none\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import cProfile\n",
    "import pstats\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b22324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoding(model_name, data):\n",
    "    \"\"\"labelEncoding function replace the categorical valeu with a numberic value from 0 and the number of classes -1.\n",
    "    Also, the label encoder object is saved as a file using Pickle package to be recalled after classification.\n",
    "\n",
    "    :param model_name: model name used in this project (e.g. \"SVM\")\n",
    "    :param data: categorical datasets\n",
    "    :return: label encoded data, lable encoder object\n",
    "    \"\"\" \n",
    "    \n",
    "    for column in data.columns:\n",
    "        # If the data type of the cell is 'object'(Categorical), it will be transformed as a numerical \n",
    "        if data[column].dtype == type(object):\n",
    "            le_file_path = 'result/' + model_name + '/' + model_name + '_' + column + '_encoder.pkl'\n",
    "            if os.path.exists(le_file_path):\n",
    "                pkl_file = open(le_file_path, 'rb')\n",
    "                le = pickle.load(pkl_file) \n",
    "                pkl_file.close()\n",
    "                data[column] = le.transform(data[column])            \n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                data[column] = le.fit_transform(data[column])\n",
    "                #exporting the departure encoder\n",
    "                output = open(le_file_path, 'wb')\n",
    "                pickle.dump(le, output)\n",
    "                output.close()\n",
    "            if column == 'result':\n",
    "                le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(le_name_mapping)\n",
    "                \n",
    "    return data, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b798dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(model_name, data):\n",
    "    \"\"\"Preprocessing function first separate datasets as input features(x) and class type 'result'(y) respectively.\n",
    "    And split dataset into train and test using splitter.\n",
    "    \n",
    "    :param model_name: model name used in this project (e.g. \"SVM\")\n",
    "    :param data: categorical datasets\n",
    "    :return: x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    y = data.result\n",
    "    x = data.drop('result', axis=1)\n",
    "    \n",
    "    # Preprocessing: Split 7:3 Train: Test\n",
    "    x_train, x_test, y_train, y_test = splitter(x, y, test_size=0.3)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7377e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model_name, x_train, x_test, y_train, y_test):\n",
    "    \"\"\"train_and_test function train the proposed model with the train dataset\n",
    "    And test it with test dataset\n",
    "    Additionally it will finalize the model to be used in the product. \n",
    "    \n",
    "    :param model_name: model name used in this project (e.g. \"SVM\")\n",
    "    :param x_train: train input features\n",
    "    :param y_train: train label\n",
    "    :param x_test: test input features\n",
    "    :param y_test: test label    \n",
    "    :return: model, y_pred is prediced lables from the model\n",
    "    \"\"\"\n",
    "\n",
    "    # Profile: Start \n",
    "    profile = cProfile.Profile()\n",
    "    profile.enable()\n",
    "    \n",
    "    # train and test\n",
    "    model = GaussianNB()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Profile: End \n",
    "    profile.disable()\n",
    "    profile.dump_stats('output.prof')\n",
    "    stream = open('result/' + model_name + '/' + model_name + '_profiling.txt', 'w')\n",
    "    stats = pstats.Stats('output.prof', stream=stream)\n",
    "    stats.sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    os.remove('output.prof')\n",
    "    \n",
    "    # Freezing model for production \n",
    "    dump(model, 'result/' + model_name + '/' + model_name + '_model.joblib') \n",
    "    \n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba6acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model_name, y_test, y_pred, le=None):\n",
    "    \"\"\"report function evaluates the quality of the output of a classifier on this data set.\n",
    "    We can get the value of Precision, Recall,, F1-Score, Support, accuracy by Lables \n",
    "    And it can get Multiclass AUC score multiclass using roc_auc_score_multiclass function\n",
    "    Additionally, it draws Bar graph about comparison between labels in each metrics (precision, recall, f1-score, AUC)\n",
    "    All are saved as a file\n",
    "    \n",
    "    :param model_name: model name used in this project (e.g. \"SVM\")\n",
    "    :param y_test: test label    \n",
    "    :param y_pred: test label    \n",
    "    :param le: None or Label encoder    \n",
    "    :return: _confusion_matrix, _classification_report, _auc_dict, _classification_report_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estimation: Confusion Matrix & classification-report \n",
    "    _confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    _classification_report = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=False)\n",
    "    _classification_report_dict = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "    # For Multiclass AUC\n",
    "    _auc_dict = roc_auc_score_multiclass(y_test, y_pred)\n",
    "    _auc_dict = dict((le.classes_[key], value) for (key, value) in _auc_dict.items())\n",
    "#     _auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "#     _fpr, _tpr, _thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "    with open('result/' + model_name + '/' + model_name + '_output.txt', 'w') as f:\n",
    "        f.write(\"\\n---Confusion Matrix---\\n\")\n",
    "        f.write(np.array2string(_confusion_matrix, separator=', '))\n",
    "        f.write(\"\\n---Classification Report---\\n\")\n",
    "        f.write(_classification_report)\n",
    "        f.write(\"\\n---ROC AUC Score---\\n\")\n",
    "        f.write(str(_auc_dict))\n",
    "#         f.write(_auc)\n",
    "    \n",
    "    print('\\n-----Confusion Matrix-----\\n')\n",
    "    print(_confusion_matrix)\n",
    "    print('\\n-----Classification Report-----\\n')\n",
    "    print(_classification_report)\n",
    "    print('\\n-----AUC Dictionary-----\\n')\n",
    "    print(str(_auc_dict))\n",
    "    \n",
    "    metrix = ['precision', 'recall', 'f1-score']\n",
    "#     metrix = ['precision', 'recall', 'f1-score', 'support']\n",
    "    xKeys = le.classes_\n",
    "    for met in metrix:\n",
    "        xValues = []\n",
    "        for target_name in le.classes_:\n",
    "            xValues += [_classification_report_dict[target_name][met]]\n",
    "\n",
    "        pyplot.title(met)\n",
    "        pyplot.bar(range(len(xValues)), list(xValues), align='center')\n",
    "        pyplot.xticks(range(len(xKeys)), list(xKeys))\n",
    "        pyplot.show()\n",
    "\n",
    "    pyplot.title('AUC')\n",
    "    pyplot.bar(range(len(_auc_dict)), list(_auc_dict.values()), align='center')\n",
    "    pyplot.xticks(range(len(_auc_dict)), list(_auc_dict.keys()))\n",
    "    pyplot.show()\n",
    "    \n",
    "#     # plot the roc curve for the model\n",
    "#     # pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "#     pyplot.plot(_fpr, _tpr, marker='.', label=model_name)\n",
    "#     # axis labels\n",
    "#     pyplot.xlabel('False Positive Rate')\n",
    "#     pyplot.ylabel('True Positive Rate')\n",
    "#     # show the legend\n",
    "#     pyplot.legend()\n",
    "#     # show the plot\n",
    "#     pyplot.show()\n",
    "    \n",
    "    return _confusion_matrix, _classification_report, _auc_dict, _classification_report_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44318c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_multiclass(y_test, y_pred, average = \"macro\"):\n",
    "    \"\"\"roc_auc_score_multiclass function evaluate the multiclass output as a ROC AUC score.\n",
    "    \n",
    "    :param y_test: test label    \n",
    "    :param y_pred: test label    \n",
    "    :param average: \"macro\" or Label encoder    \n",
    "    :return: _confusion_matrix, _classification_report, _auc_dict, _classification_report_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    unique_class = set(y_test)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_y_test = [0 if x in other_class else 1 for x in y_test]\n",
    "        new_y_pred = [0 if x in other_class else 1 for x in y_pred]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_y_test, new_y_pred, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "    return roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4ee412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(model_name, data):\n",
    "    \"\"\"production function receive real network traffic data from the product \n",
    "    And classify it with saved label encoder and the model\n",
    "    \n",
    "    :param model_name: model name    \n",
    "    :param data: real dataset     \n",
    "    :return: pred_label, real_label\n",
    "    \"\"\"\n",
    "    real_data, le = labelEncoding(model_name, data)\n",
    "    real_y = real_data.result\n",
    "    real_x = real_data.drop('result', axis=1)\n",
    "#     print(real_y)\n",
    "#     print(real_x)\n",
    "\n",
    "    clf = load('result/' + model_name + '/' + model_name + '_model.joblib')\n",
    "    yy_pred = clf.predict(real_x)\n",
    "    pred_label = le.inverse_transform(yy_pred)\n",
    "    real_label = le.inverse_transform(real_y)\n",
    "\n",
    "    return pred_label, real_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a8ce1",
   "metadata": {},
   "source": [
    "# Run Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007971f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \"\"\"Receive Input datasets\"\"\"\n",
    "    model_name = 'gnb_kdd'\n",
    "    # model_name = 'gnd_nsl_kdd'\n",
    "    dataset_name = 'kdd_prediction'\n",
    "    # dataset_name = 'kdd_prediction_NSL'\n",
    "\n",
    "    data = pd.read_csv('./dataset/' + dataset_name + '.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "#     print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f056c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dos': 0, 'normal': 1, 'probe': 2, 'r2l': 3, 'u2r': 4}\n"
     ]
    }
   ],
   "source": [
    "    \"\"\"Label Encoding for categorical datasets\"\"\"\n",
    "    data, le = labelEncoding(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41e0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Preprocessing\"\"\"\n",
    "    x_train, x_test, y_train, y_test = Preprocessing(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffae685",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Train and Test\"\"\"\n",
    "    model, y_pred = train_and_test(model_name, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c4d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Confusion Matrix-----\n",
      "\n",
      "[[  69    0 1422    9    0]\n",
      " [1677   13  216   12  333]\n",
      " [   0    0  160    1    0]\n",
      " [   1    2    2   99    2]\n",
      " [   1    2    1    2   12]]\n",
      "\n",
      "-----Classification Report-----\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dos       0.04      0.05      0.04      1500\n",
      "      normal       0.76      0.01      0.01      2251\n",
      "       probe       0.09      0.99      0.16       161\n",
      "         r2l       0.80      0.93      0.86       106\n",
      "         u2r       0.03      0.67      0.07        18\n",
      "\n",
      "    accuracy                           0.09      4036\n",
      "   macro avg       0.35      0.53      0.23      4036\n",
      "weighted avg       0.47      0.09      0.05      4036\n",
      "\n",
      "\n",
      "-----AUC Dictionary-----\n",
      "\n",
      "{'dos': 0.19196687697160883, 'normal': 0.5017671573293911, 'probe': 0.7851524744540171, 'r2l': 0.9639276969609679, 'u2r': 0.7916459266633482}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RYANJO~1\\AppData\\Local\\Temp/ipykernel_16508/15456081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"Report\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\RYANJO~1\\AppData\\Local\\Temp/ipykernel_16508/3591659305.py\u001b[0m in \u001b[0;36mreport\u001b[1;34m(model_name, y_test, y_pred, le)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mxValues\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_classification_report_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxKeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxKeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyplot' is not defined"
     ]
    }
   ],
   "source": [
    "    \"\"\"Report\"\"\"\n",
    "    cm, cr, auc, _ = report(model_name, y_test, y_pred, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"Production\"\"\"\n",
    "    real_data = pd.read_csv('./dataset/kdd_prediction.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "    real_data = real_data.head(1)\n",
    "\n",
    "    pred_label, real_label = production(model_name, real_data)\n",
    "    print(pred_label, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b274d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
