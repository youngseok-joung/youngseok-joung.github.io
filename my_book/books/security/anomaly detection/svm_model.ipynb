{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692660fb",
   "metadata": {},
   "source": [
    "# Support-vector machine\n",
    "\n",
    "## I want to classify something well!\n",
    "> I can classify real objects in real world by my eyes and hands.\n",
    "> How about entangible things like numbers, positions, attributes, types\n",
    "\n",
    "### Which shape is the best in a specific Dimension?\n",
    "\n",
    "1. How could we devide two points in a 1D by a point?\n",
    "Imagine that if there are different two points in a line.\n",
    "Which position of a new point is proper to divide the two points below?\n",
    "\n",
    "![1d.PNG](./assets/images/1d.PNG)\n",
    "\n",
    "2. How could we devide two points in a 2D by a line?\n",
    "\n",
    "![2d.PNG](./assets/images/2d.PNG)\n",
    "\n",
    "\n",
    "3. How could we devide two points in a 3D by a plane?\n",
    "\n",
    "![3d.PNG](./assets/images/3d.PNG)\n",
    "\n",
    "### Where is the best position of the shape? \n",
    "\n",
    "1. The place Where it is the middle of the two points.\n",
    "\n",
    "\n",
    "## Support-vector classification\n",
    "More formally, a support-vector machine **constructs a hyperplane** or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks like outliers detection.[3] \n",
    "\n",
    "> Intuitively, a good separation is achieved by *he hyperplane that has the largest distance to the nearest training-data point of any class (so-called functional margin), since in general the larger the margin, the lower the generalization error of the classifier.[4]\n",
    "\n",
    "The objective of the support vector machine algorithm is to find a hyperplane(N-1 D Subspace) in an N-dimensional space(N â€” the number of features) that distinctly classifies the data points. (https://en.wikipedia.org/wiki/Support-vector_machine)\n",
    "\n",
    "### Hyperplane \n",
    "In geometry, a hyperplane is a subspace whose dimension is **one less** than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines. (https://en.wikipedia.org/wiki/Hyperplane)\n",
    "\n",
    "### Maximum-margin \n",
    "Maximum-margin hyperplane and margins for an SVM trained with samples from two classes. Samples on the margin are called the support vectors. (https://en.wikipedia.org/wiki/Support-vector_machine)\n",
    "\n",
    "![SVM_margin.PNG](./assets/images/SVM_margin.PNG)\n",
    "\n",
    "\n",
    "### Problem: Not linearly separable in that space (Curved like below)\n",
    "1. Kernal function is to keep the computational load reasonable, the mappings used by SVM schemes are designed to ensure that dot products of pairs of input data vectors may be computed easily in terms of the variables in the original space\n",
    "\n",
    "![kernal_function.PNG](./assets/images/1920px-Kernel_Machine.svg.PNG)\n",
    "\n",
    "2.  a set of vectors is an orthogonal (and thus minimal) set of vectors that defines a hyperplane. The vectors defining the hyperplanes can be chosen to be linear combinations with parameters {\\displaystyle \\alpha _{i}}\\alpha _{i} of images of feature vectors {\\displaystyle x_{i}}x_{i} that occur in the data bas\n",
    "\n",
    "### Hinge Loss function\n",
    "To extend SVM to cases in which the data are not linearly separable, the hinge loss function is helpful\n",
    "\n",
    "![hinge_loss.PNG](./assets/images/hinge_loss.PNG)\n",
    "\n",
    "The goal of the optimization then is to minimize\n",
    "\n",
    "![optimization_function.PNG](./assets/images/optimization_function.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6561f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"svm_model.py: \n",
    "\n",
    "This model is the implementation of Classification of KDD datasets.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Youngseok Joung'\n",
    "__copyright__ = \"Copyright 2021, The Cogent Project\"\n",
    "__credits__ = [\"Youngseok Joung\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.1\"\n",
    "__maintainer__ = \"Youngseok Joung\"\n",
    "__email__ = \"none\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "from sklearn.svm import SVC\n",
    "import cProfile\n",
    "import pstats\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262acc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoding(model_name, data):\n",
    "    for column in data.columns:\n",
    "        # If the data type of the cell is 'object'(Categorical), it will be transformed as a numerical \n",
    "        if data[column].dtype == type(object):\n",
    "            le_file_path = 'result/' + model_name + '/' + model_name + '_' + column + '_encoder.pkl'\n",
    "            if os.path.exists(le_file_path):\n",
    "                pkl_file = open(le_file_path, 'rb')\n",
    "                le = pickle.load(pkl_file) \n",
    "                pkl_file.close()\n",
    "                data[column] = le.transform(data[column])            \n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                data[column] = le.fit_transform(data[column])\n",
    "                #exporting the departure encoder\n",
    "                output = open(le_file_path, 'wb')\n",
    "                pickle.dump(le, output)\n",
    "                output.close()\n",
    "            if column == 'result':\n",
    "                le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(le_name_mapping)\n",
    "    return data, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6518391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(model_name, data):\n",
    "    y = data.result\n",
    "    x = data.drop('result', axis=1)\n",
    "    \n",
    "    # Preprocessing: Split 7:3 Train: Test\n",
    "    x_train, x_test, y_train, y_test = splitter(x, y, test_size=0.3)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89da868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model_name, x_train, x_test, y_train, y_test):\n",
    "    # Profile: Start \n",
    "    profile = cProfile.Profile()\n",
    "    profile.enable()\n",
    "    \n",
    "    # train and test\n",
    "    model = SVC()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Profile: End \n",
    "    profile.disable()\n",
    "    profile.dump_stats('output.prof')\n",
    "    stream = open('result/' + model_name + '/' + model_name + '_profiling.txt', 'w')\n",
    "    stats = pstats.Stats('output.prof', stream=stream)\n",
    "    stats.sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    os.remove('output.prof')\n",
    "    \n",
    "    # Estimation: Confusion Matrix & classification-report \n",
    "    _confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    _classification_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    with open('result/' + model_name + '/' + model_name + '_output.txt', 'w') as f:\n",
    "        f.write(\"\\n---Confusion Matrix---\\n\")\n",
    "        f.write(np.array2string(_confusion_matrix, separator=', '))\n",
    "        f.write(\"\\n---Classification Report---\\n\")\n",
    "        f.write(_classification_report)\n",
    "\n",
    "    # Freezing model for production \n",
    "    dump(model, 'result/' + model_name + '/' + model_name + '_model.joblib') \n",
    "    \n",
    "    return _confusion_matrix, _classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5090ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        duration protocol_type   service  flag  src_bytes  dst_bytes      land  \\\n",
      "0     -0.106216           tcp      smtp    SF  -0.003736  -0.040352 -0.011722   \n",
      "1     -0.107850           tcp      http    SF  -0.004276  -0.036652 -0.011722   \n",
      "2     -0.107850           tcp      http    SF  -0.004262   0.005956 -0.011722   \n",
      "3     -0.107033           tcp       ftp    SF  -0.003699  -0.006723 -0.011722   \n",
      "4     -0.107850           udp  domain_u    SF  -0.004368  -0.044940 -0.011722   \n",
      "...         ...           ...       ...   ...        ...        ...       ...   \n",
      "13446 -0.107850           tcp      http    SF  -0.004225   0.049683 -0.011722   \n",
      "13447 -0.107850           tcp      nntp  RSTO  -0.004392  -0.047028 -0.011722   \n",
      "13448 -0.107033           tcp      smtp    SF  -0.003734  -0.041519 -0.011722   \n",
      "13449 -0.107850           tcp      nnsp   REJ  -0.004392  -0.047028 -0.011722   \n",
      "13450 -0.107850           tcp      link    S0  -0.004392  -0.047028 -0.011722   \n",
      "\n",
      "       wrong_fragment    urgent        hot  ...  num_compromised  root_shell  \\\n",
      "0           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "1           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "2           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "3           -0.084394 -0.004737  19.554084  ...        -0.007905    -0.01944   \n",
      "4           -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "...               ...       ...        ...  ...              ...         ...   \n",
      "13446       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13447       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13448       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13449       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "13450       -0.084394 -0.004737  -0.070210  ...        -0.007905    -0.01944   \n",
      "\n",
      "       su_attempted  num_root  num_file_creations  num_shells  \\\n",
      "0         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "1         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "2         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "3         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "4         -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "...             ...       ...                 ...         ...   \n",
      "13446     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13447     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13448     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13449     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "13450     -0.008613  -0.01039           -0.020694   -0.018274   \n",
      "\n",
      "       num_access_files  is_guest_login     count  result  \n",
      "0             -0.050883       -0.068756 -0.731403  normal  \n",
      "1             -0.050883       -0.068756 -0.681570  normal  \n",
      "2             -0.050883       -0.068756 -0.711470  normal  \n",
      "3             -0.050883       14.544119 -0.731403     r2l  \n",
      "4             -0.050883       -0.068756 -0.302843  normal  \n",
      "...                 ...             ...       ...     ...  \n",
      "13446         -0.050883       -0.068756 -0.243044  normal  \n",
      "13447         -0.050883       -0.068756  0.484511     dos  \n",
      "13448         -0.050883       -0.068756 -0.731403  normal  \n",
      "13449         -0.050883       -0.068756  0.265248     dos  \n",
      "13450         -0.050883       -0.068756  1.929653     dos  \n",
      "\n",
      "[13451 rows x 22 columns]>\n"
     ]
    }
   ],
   "source": [
    "model_name = 'svm_kdd'\n",
    "# model_name = 'svm_nsl_kdd'\n",
    "dataset_name = 'kdd_prediction'\n",
    "# dataset_name = 'kdd_prediction_NSL'\n",
    "\n",
    "data = pd.read_csv('./dataset/' + dataset_name + '.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8355e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dos': 0, 'normal': 1, 'probe': 2, 'r2l': 3, 'u2r': 4}\n"
     ]
    }
   ],
   "source": [
    "# labeling\n",
    "data, _ = labelEncoding(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca9bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "x_train, x_test, y_train, y_test = Preprocessing(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1344853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Confusion Matrix-----\n",
      "\n",
      "[[1491    9    0    0    0]\n",
      " [   5 2258    0    4    0]\n",
      " [  92   40   22    0    0]\n",
      " [   0    9    0   89    1]\n",
      " [   0    8    0    0    8]]\n",
      "\n",
      "-----Classification Report-----\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      1500\n",
      "           1       0.97      1.00      0.98      2267\n",
      "           2       1.00      0.14      0.25       154\n",
      "           3       0.96      0.90      0.93        99\n",
      "           4       0.89      0.50      0.64        16\n",
      "\n",
      "    accuracy                           0.96      4036\n",
      "   macro avg       0.95      0.71      0.75      4036\n",
      "weighted avg       0.96      0.96      0.95      4036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and Test\n",
    "cm, cr = train_and_test(model_name, x_train, x_test, y_train, y_test)\n",
    "print('\\n-----Confusion Matrix-----\\n')\n",
    "print(cm)\n",
    "print('\\n-----Classification Report-----\\n')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8adac2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(model_name, data):\n",
    "    real_data, le = labelEncoding(model_name, data)\n",
    "    real_y = real_data.result\n",
    "    real_x = real_data.drop('result', axis=1)\n",
    "#     print(real_y)\n",
    "#     print(real_x)\n",
    "\n",
    "    clf = load('result/' + model_name + '/' + model_name + '_model.joblib')\n",
    "    yy_pred = clf.predict(real_x)\n",
    "    pred_label = le.inverse_transform(yy_pred)\n",
    "    real_label = le.inverse_transform(real_y)\n",
    "\n",
    "    return pred_label, real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27933acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dos': 0, 'normal': 1, 'probe': 2, 'r2l': 3, 'u2r': 4}\n",
      "['normal'] ['normal']\n"
     ]
    }
   ],
   "source": [
    "# Production\n",
    "real_data = pd.read_csv('./dataset/kdd_prediction.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "real_data = real_data.head(1)\n",
    "\n",
    "pred_label, real_label = production(model_name, real_data)\n",
    "print(pred_label, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272bff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
