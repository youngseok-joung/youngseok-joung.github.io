{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de103ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"keras_model.py: \n",
    "\n",
    "This model is the implementation of Gaussian Naive Bayes Classification of KDD datasets.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Youngseok Joung'\n",
    "__copyright__ = \"Copyright 2007, The Cogent Project\"\n",
    "__credits__ = [\"Youngseok Joung\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.1\"\n",
    "__maintainer__ = \"Youngseok Joung\"\n",
    "__email__ = \"none\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as splitter\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import cProfile\n",
    "import pstats\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b22324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelEncoding(model_name, data):\n",
    "    for column in data.columns:\n",
    "        # If the data type of the cell is 'object'(Categorical), it will be transformed as a numerical \n",
    "        if data[column].dtype == type(object):\n",
    "            le_file_path = 'result/' + model_name + '/' + model_name + '_' + column + '_encoder.pkl'\n",
    "            print(os.path.exists(le_file_path))\n",
    "            if os.path.exists(le_file_path):\n",
    "                pkl_file = open(le_file_path, 'rb')\n",
    "                le = pickle.load(pkl_file) \n",
    "                pkl_file.close()\n",
    "                data[column] = le.transform(data[column])            \n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                data[column] = le.fit_transform(data[column])\n",
    "                #exporting the departure encoder\n",
    "                output = open(le_file_path, 'wb')\n",
    "                pickle.dump(le, output)\n",
    "                output.close()\n",
    "            if column == 'result':\n",
    "                le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(le_name_mapping)\n",
    "                \n",
    "    return data, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(model_name, data):\n",
    "    y = data.result\n",
    "    x = data.drop('result', axis=1)\n",
    "    \n",
    "    # Preprocessing: Split 7:3 Train: Test\n",
    "    x_train, x_test, y_train, y_test = splitter(x, y, test_size=0.3)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model_name, x_train, x_test, y_train, y_test):\n",
    "    # Profile: Start \n",
    "    profile = cProfile.Profile()\n",
    "    profile.enable()\n",
    "    \n",
    "    # train and test\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    val_indices = 200\n",
    "    x_val = x_train[-val_indices:]\n",
    "    y_val = y_train[-val_indices:]\n",
    "    # train and test\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_dim=x_train.shape[1], kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=15, batch_size=512, validation_data=(x_val, y_val))\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Profile: End \n",
    "    profile.disable()\n",
    "    profile.dump_stats('output.prof')\n",
    "    stream = open('result/' + model_name + '/' + model_name + '_profiling.txt', 'w')\n",
    "    stats = pstats.Stats('output.prof', stream=stream)\n",
    "    stats.sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    os.remove('output.prof')\n",
    "    \n",
    "    # Estimation: Confusion Matrix & classification-report \n",
    "    _confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    _classification_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    with open('result/' + model_name + '/' + model_name + '_output.txt', 'w') as f:\n",
    "        f.write(\"\\n---Confusion Matrix---\\n\")\n",
    "        f.write(np.array2string(_confusion_matrix, separator=', '))\n",
    "        f.write(\"\\n---Classification Report---\\n\")\n",
    "        f.write(_classification_report)\n",
    "\n",
    "    # Freezing model for production \n",
    "    dump(model, 'result/' + model_name + '/' + model_name + '_model.joblib') \n",
    "    \n",
    "    return _confusion_matrix, _classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30cebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'keras_kdd'\n",
    "# model_name = 'keras_nsl_kdd'\n",
    "dataset_name = 'kdd_prediction'\n",
    "# dataset_name = 'kdd_prediction_NSL'\n",
    "\n",
    "data = pd.read_csv('./dataset/' + dataset_name + '.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "data, _ = labelEncoding(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "x_train, x_test, y_train, y_test = Preprocessing(model_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test\n",
    "cm, cr = train_and_test(model_name, x_train, x_test, y_train, y_test)\n",
    "print('\\n-----Confusion Matrix-----\\n')\n",
    "print(cm)\n",
    "print('\\n-----Classification Report-----\\n')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def production(model_name, data):\n",
    "    real_data, le = labelEncoding(model_name, data)\n",
    "    real_y = real_data.result\n",
    "    real_x = real_data.drop('result', axis=1)\n",
    "#     print(real_y)\n",
    "#     print(real_x)\n",
    "\n",
    "    clf = load('result/' + model_name + '/' + model_name + '_model.joblib')\n",
    "    yy_pred = clf.predict(real_x)\n",
    "    pred_label = le.inverse_transform(yy_pred)\n",
    "    real_label = le.inverse_transform(real_y)\n",
    "\n",
    "    return pred_label, real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d01f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Production\n",
    "real_data = pd.read_csv('./dataset/kdd_prediction.csv', delimiter=',', dtype={'protocol_type': str, 'service': str, 'flag': str, 'result': str})\n",
    "real_data = real_data.head(1)\n",
    "\n",
    "pred_label, real_label = production(model_name, real_data)\n",
    "print(pred_label, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b274d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
